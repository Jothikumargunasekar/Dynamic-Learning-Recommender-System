{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b8d86a-0c3e-49cd-9d6e-e0887d009bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jothi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jothi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jothi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses: (623, 4)\n",
      "Reviews: (1454711, 5)\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# 1. Imports & Data Loading\n",
    "# ========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# ========================\n",
    "# 2. NLTK Downloads\n",
    "# ========================\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# ========================\n",
    "# 3. Load Data\n",
    "# ========================\n",
    "courses = pd.read_csv(\"Coursera_courses.csv\")\n",
    "reviews = pd.read_csv(\"Coursera_reviews.csv\")\n",
    "print(\"Courses:\", courses.shape)\n",
    "print(\"Reviews:\", reviews.shape)\n",
    "\n",
    "# ========================\n",
    "# 4. Preprocess Reviews\n",
    "# ========================\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in text.split() if w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "reviews[\"clean_review\"] = reviews[\"reviews\"].astype(str).apply(clean_text)\n",
    "\n",
    "# Label from rating\n",
    "def label_from_rating(r):\n",
    "    if r >= 4: return 1\n",
    "    elif r <= 2: return -1\n",
    "    else: return 0\n",
    "\n",
    "reviews[\"label\"] = reviews[\"rating\"].apply(label_from_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d71981-da46-4439-b6e7-411de3c7849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Cell 1: Train Logistic Regression\n",
    "# ========================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Sample for speed\n",
    "sample_size = 5000\n",
    "X = reviews[\"clean_review\"][:sample_size]\n",
    "y = reviews[\"label\"][:sample_size]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=500)\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict & F1\n",
    "y_pred = logreg.predict(X_test_tfidf)\n",
    "f1_logreg = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print(f\"Logistic Regression F1-score: {f1_logreg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e26cc6bc-c223-4c83-b49f-7dcc39130807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1-score: 0.5171\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Cell 2: Train Naive Bayes\n",
    "# ========================\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test_tfidf)\n",
    "f1_nb = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print(f\"Naive Bayes F1-score: {f1_nb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd89026-bdc4-479f-bad0-aceb0ae18aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Cell 3: Train Random Forest\n",
    "# ========================\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test_tfidf)\n",
    "f1_rf = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print(f\"Random Forest F1-score: {f1_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251694f4-9141-4e6f-9274-3af9180460ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Cell 4: Train SVM\n",
    "# ========================\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test_tfidf)\n",
    "f1_svm = f1_score(y_test, y_pred, average=\"macro\")\n",
    "print(f\"SVM F1-score: {f1_svm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c1acb-4052-4165-82aa-17fca8eadfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Cell 5: Train XGBoost\n",
    "# ========================\n",
    "import xgboost as xgb\n",
    "\n",
    "y_train_xgb = y_train.map({-1:0, 0:1, 1:2})\n",
    "y_test_xgb = y_test.map({-1:0, 0:1, 1:2})\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(eval_metric=\"mlogloss\", use_label_encoder=False)\n",
    "xgb_model.fit(X_train_tfidf, y_train_xgb)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test_tfidf)\n",
    "y_pred_xgb_orig = pd.Series(y_pred_xgb).map({0:-1,1:0,2:1})\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb_orig, average=\"macro\")\n",
    "print(f\"XGBoost F1-score: {f1_xgb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb25f8-4908-429d-adc5-98ce2f066920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Cell 6: VADER\n",
    "# ========================\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_label(text):\n",
    "    score = sid.polarity_scores(text)[\"compound\"]\n",
    "    if score >= 0.05: return 1\n",
    "    elif score <= -0.05: return -1\n",
    "    else: return 0\n",
    "\n",
    "y_pred_vader = X_test.apply(vader_label)\n",
    "f1_vader = f1_score(y_test, y_pred_vader, average=\"macro\")\n",
    "print(f\"VADER F1-score: {f1_vader:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40f14f-f699-4b3e-9b35-78424545ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Cell 7: BERT\n",
    "# ========================\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "bert_classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "label_map = {\"LABEL_0\":-1, \"LABEL_1\":0, \"LABEL_2\":1}\n",
    "\n",
    "# Quick test on sample\n",
    "sample_texts = list(X_test[:10])\n",
    "bert_preds = [label_map[bert_classifier(t[:512])[0][\"label\"]] for t in sample_texts]\n",
    "f1_bert = f1_score(y_test[:10], bert_preds, average=\"macro\")\n",
    "print(f\"BERT F1-score (sample): {f1_bert:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b128d19-e4cb-44bb-b698-112ee55952bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Cell 8: Choose Best Model\n",
    "# ========================\n",
    "\n",
    "f1_scores = {\n",
    "    \"LogReg\": f1_logreg,\n",
    "    \"NaiveBayes\": f1_nb,\n",
    "    \"RandomForest\": f1_rf,\n",
    "    \"SVM\": f1_svm,\n",
    "    \"XGBoost\": f1_xgb,\n",
    "    \"VADER\": f1_vader,\n",
    "    \"BERT\": f1_bert\n",
    "}\n",
    "\n",
    "best_model_name = max(f1_scores, key=f1_scores.get)\n",
    "\n",
    "if best_model_name == \"XGBoost\":\n",
    "    final_model = xgb_model\n",
    "elif best_model_name == \"VADER\":\n",
    "    final_model = \"VADER\"\n",
    "elif best_model_name == \"BERT\":\n",
    "    final_model = bert_classifier\n",
    "elif best_model_name in [\"LogReg\",\"NaiveBayes\",\"RandomForest\",\"SVM\"]:\n",
    "    final_model = {\"LogReg\":logreg,\"NaiveBayes\":nb,\"RandomForest\":rf,\"SVM\":svm}[best_model_name]\n",
    "\n",
    "print(f\" Best Model Selected: {best_model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac28edc-7923-49a8-a841-244a8657ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# Cell 9: Sentiment + Course Ranking\n",
    "# ========================\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    text_clean = clean_text(text)\n",
    "    if final_model==\"VADER\":\n",
    "        return vader_label(text_clean)\n",
    "    elif best_model_name==\"BERT\":\n",
    "        return label_map[final_model(text_clean[:512])[0][\"label\"]]\n",
    "    elif best_model_name==\"XGBoost\":\n",
    "        pred = final_model.predict(tfidf.transform([text_clean]))[0]\n",
    "        return {-1:-1,0:0,1:1,2:1}[pred]\n",
    "    else:\n",
    "        return final_model.predict(tfidf.transform([text_clean]))[0]\n",
    "\n",
    "# 1️⃣ Single Review\n",
    "user_text = input(\"Enter a review text: \")\n",
    "pred_label = predict_sentiment(user_text)\n",
    "label_map_text = {1:\"Positive\",0:\"Neutral\",-1:\"Negative\"}\n",
    "print(f\"\\nSentiment: {label_map_text[pred_label]} ({pred_label})\")\n",
    "\n",
    "# 2️⃣ Course Ranking\n",
    "keyword = input(\"\\nEnter a course keyword: \").lower()\n",
    "\n",
    "# Predict sentiment for all reviews\n",
    "reviews[\"pred_label\"] = reviews[\"clean_review\"].apply(predict_sentiment)\n",
    "\n",
    "# Aggregate per course\n",
    "course_summary = reviews.groupby(\"course_id\")[\"pred_label\"].agg(\n",
    "    avg_score=\"mean\",\n",
    "    pos_pct=lambda x: (x==1).mean()*100,\n",
    "    neu_pct=lambda x: (x==0).mean()*100,\n",
    "    neg_pct=lambda x: (x==-1).mean()*100,\n",
    "    polarity=lambda x: x.std()  # high std = polarized\n",
    ").reset_index()\n",
    "\n",
    "course_summary = course_summary.merge(\n",
    "    courses[[\"course_id\",\"course_title\"]], on=\"course_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Filter keyword\n",
    "filtered = course_summary[course_summary[\"course_title\"].str.lower().str.contains(keyword)]\n",
    "filtered_sorted = filtered.sort_values(\"avg_score\", ascending=False)\n",
    "\n",
    "# Print with mixed review handling\n",
    "print(f\"\\nTop courses for '{keyword}':\\n\")\n",
    "for _, row in filtered_sorted.iterrows():\n",
    "    polar_flag = \"⚡ Polarized\" if row[\"polarity\"]>0.5 else \"\"\n",
    "    print(f\"{row['course_title']}  --> Avg: {row['avg_score']:.2f} | \"\n",
    "          f\"Pos: {row['pos_pct']:.1f}%  Neu: {row['neu_pct']:.1f}%  Neg: {row['neg_pct']:.1f}% {polar_flag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad86a1e-5a4e-4b92-a3f6-7b0ead888b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
